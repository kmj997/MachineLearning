{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set torch basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Set dtype\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=True,\n",
    "    download=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=False,\n",
    "    download=True)\n",
    "\n",
    "\n",
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename tensors\n",
    "X_train = mnist_train.data\n",
    "y_train = mnist_train.targets\n",
    "X_test = mnist_test.data\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "# Check the shape of data and labels\n",
    "print(\"Train data shape : \", X_train.shape)\n",
    "print(\"Train label shape : \", y_train.shape)\n",
    "print(\"Test data shape : \", X_test.shape)\n",
    "print(\"Test label shape : \", y_test.shape)\n",
    "\n",
    "# Show a image example\n",
    "# Generate random number\n",
    "# Fill the code\n",
    "\n",
    "# Show the image with label as title\n",
    "# Fill the code\n",
    "\n",
    "\n",
    "# Show image with computer's perspective\n",
    "print(str(y_train[idx].numpy()) + \"'s image data\\n\")\n",
    "print(X_train[idx])\n",
    "\n",
    "# Convert data to double cuda tensor\n",
    "X_train = X_train.to(dtype=dtype, device=device)\n",
    "y_train = y_train.to(device=device)\n",
    "X_test = X_test.to(dtype=dtype, device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorization and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE THIS CELL REPEATEDLY! UNEXPECTED RESULTS CAN BE SHOWN!\n",
    "# Calculate vector size\n",
    "def calculate_vector_size(data_size):\n",
    "    # Calculate vector size from data shape\n",
    "    \n",
    "    # Arguments\n",
    "    # data_size : shape of the data\n",
    "    \n",
    "    # Fill the code\n",
    "    \n",
    "    return size\n",
    "\n",
    "# Normalize with minimax normalizer\n",
    "def normalize(data, min_value, max_value):\n",
    "    # Minimax normalizer\n",
    "    \n",
    "    # Arguments\n",
    "    # data : Image data\n",
    "    # min_value : The lowest value in the data\n",
    "    # max_value : The largest value in the data\n",
    "    \n",
    "    # Fill the code\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Check data shape\n",
    "shape = X_train.shape[1:] # 0 index is number of data\n",
    "print(\"Data shape : \", shape)\n",
    "\n",
    "# Vectorize the data\n",
    "X_train =  # Vectorize the X_train\n",
    "X_test =  # Vectorize the X_test\n",
    "\n",
    "# Normalized the data\n",
    "# Each pixel has 0 ~ 255 value for their intensivity\n",
    "X_train =  # Normalize the X_train data\n",
    "X_test =  # Normalize the X_test data\n",
    "\n",
    "# Check changes on data\n",
    "idx = np.random.randint(0, y_train.shape[0])\n",
    "print(str(idx + 1) + \"th data in X_train\\n\", X_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate 10 x 10 identity matrix\n",
    "print(\"10 x 10 identity matrix \\n\", torch.eye(10))\n",
    "\n",
    "# Sparse label\n",
    "sparse_label = torch.tensor([1, 3, 5, 7, 9])\n",
    "print(\"Sparse label \\n\", sparse_label)\n",
    "\n",
    "# Sparse label -> one-hot vector\n",
    "print(\"One-hot vector \\n\", torch.eye(10)[sparse_label]) # Output is double tensor\n",
    "\n",
    "# Simple method\n",
    "print(\"One-hot vector (Simple version) \\n\", torch.nn.functional.one_hot(sparse_label)) # Output is long tensor\n",
    "\n",
    "# Change mnist dataset's label to one hot vector without torch.nn.functional and set the dtype and device\n",
    "\n",
    "# Fill the code\n",
    "\n",
    "\n",
    "# Check the changes\n",
    "print(\"train label one hot vector's shape : \", y_train_one_hot.shape)\n",
    "idx = np.random.randint(0, y_train.shape[0])\n",
    "print(\"train one hot vector example, \" + str(idx) + \"th label\")\n",
    "print(y_train_one_hot[idx])\n",
    "\n",
    "print(\"test label one hot vector's shape : \", y_test_one_hot.shape)\n",
    "idx = np.random.randint(0, y_test.shape[0])\n",
    "print(\"test one hot vector example, \" + str(idx) + \"th label\")\n",
    "print(y_test_one_hot[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 100\n",
    "display_step = 10\n",
    "\n",
    "# Data dimension\n",
    "D_in =  # Data input's dimension\n",
    "D_out =  # Data output's dimemsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "class LogisticModel(torch.nn.Module):\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(LogisticModel, self).__init__()\n",
    "        # Initialize model weights\n",
    "        \n",
    "        # Arguments\n",
    "        # D_in : Input dimension of the model\n",
    "        # D_out : Output dimension of the model\n",
    "        \n",
    "        # Hints\n",
    "        # torch.nn.Softmax(dim)\n",
    "        # Reference : https://pytorch.org/docs/stable/nn.html?highlight=torch.nn.softmax#torch.nn.Softmax\n",
    "        \n",
    "        # Fill the code\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Calculate the model outputs\n",
    "        \n",
    "        # Arguments\n",
    "        # x : Input of the model (vectorized data)\n",
    "        \n",
    "        # Fill the code\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Define the loss using one-hot vector\n",
    "class Cross_Entropy_Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cross_Entropy_Loss, self).__init__()\n",
    "    def forward(self, y_pred, y):\n",
    "        # Loss for each example\n",
    "\n",
    "        # Mean the loss of each example\n",
    "\n",
    "        return loss\n",
    "    \n",
    "# Make the model\n",
    "\n",
    "\n",
    "# Set the loss function as Cross_Entropy_Loss\n",
    "\n",
    "\n",
    "# Set the optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    # Initialize the optimizer\n",
    "    \n",
    "    # Compute Forward process and calculate the loss\n",
    "\n",
    "    # Record the loss\n",
    "    \n",
    "    # Display the loss\n",
    "    \n",
    "    # Compute backward process and update weights\n",
    "    \n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_corrects = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    # Compute the forward process\n",
    "    \n",
    "    # Get predicted labels from outputs\n",
    "    # Hint : torch.max or torch.argmax\n",
    "    \n",
    "    # Check the number of correct labels and total label\n",
    "    \n",
    "    # Show the accuracy\n",
    "    print(\"Test accuracy : \", (test_corrects / test_total) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix's input is numpy object!\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Calculate the outputs and extract labels from that\n",
    "    # Fill the code\n",
    "    \n",
    "    print(\"Predicted label results\")\n",
    "    print(y_test_pred)\n",
    "    print(\"Target label results\")\n",
    "    print(y_test)\n",
    "    \n",
    "    print(\"Confusion matrix result\")\n",
    "    print(confusion_matrix(y_test.cpu().numpy(), y_test_pred.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 prediction examples\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        # Make random index of test data\n",
    "        \n",
    "        # Make a prediction\n",
    "        \n",
    "        # Show a image\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        \n",
    "        # On left side, we show the random image\n",
    "        \n",
    "        # On right side, we show the model's probability prediction\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Show the predicted label and true label\n",
    "        print(\"Predicted label : \", predictions.item())\n",
    "        print(\"True label : \", y_test[idx].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler implementation (with torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model with torch.nn.Sequential\n",
    "\n",
    "# Set the loss function with torch.nn.CrossEntropyLoss((log)Softmax + NLLLoss)\n",
    "# Reference : https://pytorch.org/docs/stable/nn.html?highlight=torch.nn.crossentropyloss#torch.nn.CrossEntropyLoss\n",
    "\n",
    "# Set optimizer to gradient descent optimizer\n",
    "\n",
    "\n",
    "losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    # Initialize the optimizer\n",
    "    \n",
    "    # Compute Forward process and calculate the loss\n",
    "\n",
    "    # Record the loss\n",
    "    \n",
    "    # Display the loss\n",
    "    \n",
    "    # Compute backward process and update weights\n",
    "    \n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss (Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
