{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set torch basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Set dtype\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data/\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data/\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=True,\n",
    "    download=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=False,\n",
    "    download=True)\n",
    "\n",
    "\n",
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape :  torch.Size([60000, 28, 28])\n",
      "Train label shape :  torch.Size([60000])\n",
      "Test data shape :  torch.Size([10000, 28, 28])\n",
      "Test label shape :  torch.Size([10000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8's image data\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 184, 253, 204,  83,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
      "         177, 253, 252, 252, 206,  23,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 172,\n",
      "         252, 253, 252, 252, 252,  53,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160, 252,\n",
      "         252, 215,  46, 230, 252,  53,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 233, 252,\n",
      "         217,  28,   0, 226, 231,  39,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 173, 252, 242,\n",
      "          31,   0,  80, 245, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 173, 252, 147,\n",
      "           0,  20, 200, 252, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 173, 252, 106,\n",
      "           0, 121, 252, 242,  84,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 173, 252, 106,\n",
      "           8, 197, 252,  82,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 252, 183,\n",
      "         196, 253, 195,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 209, 253,\n",
      "         253, 255,  83,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160, 252,\n",
      "         252, 202,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160, 252,\n",
      "         252, 178,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  77, 238, 252,\n",
      "         252, 253, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 236, 252, 241,\n",
      "          53, 253, 230,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 252, 246, 121,\n",
      "          54, 253, 252,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 252, 154,  14,\n",
      "         252, 253, 252,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 252, 242, 165,\n",
      "         252, 253, 170,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 206, 252, 252,\n",
      "         252, 176,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  82, 203, 174,\n",
      "         119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Rename tensors\n",
    "X_train = mnist_train.data # images\n",
    "y_train = mnist_train.targets # labels\n",
    "X_test = mnist_test.data\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "# Check the shape of data and labels\n",
    "print(\"Train data shape : \", X_train.shape)\n",
    "print(\"Train label shape : \", y_train.shape)\n",
    "print(\"Test data shape : \", X_test.shape)\n",
    "print(\"Test label shape : \", y_test.shape)\n",
    "\n",
    "# Show a image example\n",
    "# Generate random number\n",
    "idx = np.random.randint(0, X_train.size(0))\n",
    "\n",
    "# Show the image with label as title\n",
    "# Warning? : imshow uses numpy object basically\n",
    "plt.figure()\n",
    "plt.imshow(X_train[idx], cmap=\"gray\")\n",
    "plt.title(str(y_train[idx].numpy()))\n",
    "plt.show()\n",
    "\n",
    "# Show image with computer's perspective\n",
    "print(str(y_train[idx].numpy()) + \"'s image data\\n\")\n",
    "print(X_train[idx])\n",
    "\n",
    "# Convert data to double cuda tensor\n",
    "X_train = X_train.to(dtype=dtype, device=device)\n",
    "y_train = y_train.to(device=device)\n",
    "X_test = X_test.to(dtype=dtype, device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorization and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape :  torch.Size([784])\n",
      "torch.Size([60000, 784])\n",
      "torch.Size([10000, 784])\n",
      "42936th data in X_train\n",
      " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.5843, 0.9922, 0.7216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.5765, 0.9922, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1020, 0.9255, 0.9922, 0.8549, 0.0745, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1020, 0.7961, 0.9882, 0.9608, 0.3098, 0.0000, 0.0000,\n",
      "        0.0000, 0.2000, 0.3647, 0.3647, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4784, 0.9882, 0.9882, 0.2863, 0.0000, 0.0000,\n",
      "        0.3725, 0.8627, 0.9529, 0.9882, 0.9882, 0.5882, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.9922, 0.2941, 0.0118, 0.4627,\n",
      "        0.9922, 0.9922, 0.9922, 0.9059, 0.9020, 0.7804, 0.2902, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1412, 0.8588, 0.9882, 0.6745, 0.2000, 0.4627,\n",
      "        0.9882, 0.8549, 0.6431, 0.3608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9882, 0.7922, 0.4392, 0.9647,\n",
      "        0.8431, 0.6353, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.9922, 0.9216, 0.2510, 0.3137,\n",
      "        0.2196, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8627, 0.9922, 0.4000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9059, 1.0000, 0.4039,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6157, 0.9922,\n",
      "        0.9255, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255,\n",
      "        0.9922, 0.9882, 0.9176, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4588, 0.9882, 0.9882, 0.9255, 0.2392, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.3725, 0.0000,\n",
      "        0.0000, 0.0000, 0.0118, 0.4588, 0.9882, 0.9882, 0.9490, 0.4157, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8118,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7490, 0.9922, 0.9922, 0.4549,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
      "        0.9255, 0.1725, 0.0000, 0.0000, 0.2235, 0.6980, 0.9882, 0.9882, 0.9882,\n",
      "        0.3725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0941, 0.9882, 0.4667, 0.2745, 0.6824, 0.9922, 0.9882, 0.9882, 0.7647,\n",
      "        0.3098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0588, 0.8588, 0.9882, 0.9882, 0.9882, 0.9922, 0.7569, 0.3020,\n",
      "        0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1412, 0.8667, 0.8235, 0.5373, 0.2941, 0.0314,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EXECUTE THIS CELL REPEATEDLY! UNEXPECTED RESULTS CAN BE SHOWN!\n",
    "# Calculate vector size\n",
    "def calculate_vector_size(data_shape): # (28, 28) -> 784\n",
    "    # Calculate vector size from data shape\n",
    "    \n",
    "    # Arguments\n",
    "    # data_size : shape of the data\n",
    "    \n",
    "    size = 1\n",
    "    for s in data_shape:\n",
    "        size *= s\n",
    "    \n",
    "    return size\n",
    "\n",
    "# Normalize with minimax normalizer\n",
    "def normalize(data, min_value, max_value):\n",
    "    # Minimax normalizer\n",
    "    \n",
    "    # Arguments\n",
    "    # data : Image data\n",
    "    # min_value : The lowest value in the data\n",
    "    # max_value : The largest value in the data\n",
    "    \n",
    "    normalized_data = (data - min_value) / (max_value - min_value)\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Check data shape\n",
    "shape = X_train.shape[1:] # 0 index is number of data\n",
    "print(\"Data shape : \", shape)\n",
    "\n",
    "# Vectorize the data\n",
    "X_train = X_train.view(-1, calculate_vector_size(shape)) # Vectorize the X_train\n",
    "X_test = X_test.view(-1, calculate_vector_size(shape))# Vectorize the X_test\n",
    "print(X_train.size())\n",
    "print(X_test.size())\n",
    "\n",
    "# Normalized the data\n",
    "# Each pixel has 0 ~ 255 value for their intensivity\n",
    "X_train = normalize(X_train, 0, 255) # Normalize the X_train data\n",
    "X_test = normalize(X_test, 0, 255) # Normalize the X_test data\n",
    "\n",
    "# Check changes on data\n",
    "idx = np.random.randint(0, y_train.shape[0])\n",
    "print(str(idx + 1) + \"th data in X_train\\n\", X_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 x 10 identity matrix \n",
      " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "Sparse label \n",
      " tensor([1, 3, 5, 7, 9])\n",
      "One-hot vector \n",
      " tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "One-hot vector (Simple version) \n",
      " tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "train label one hot vector's shape :  torch.Size([60000, 10])\n",
      "train one hot vector example, 30025th label\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "test label one hot vector's shape :  torch.Size([10000, 10])\n",
      "test one hot vector example, 1122th label\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 x 10 identity matrix\n",
    "print(\"10 x 10 identity matrix \\n\", torch.eye(10))\n",
    "\n",
    "# Sparse label\n",
    "sparse_label = torch.tensor([1, 3, 5, 7, 9])\n",
    "print(\"Sparse label \\n\", sparse_label)\n",
    "\n",
    "# Sparse label -> one-hot vector\n",
    "print(\"One-hot vector \\n\", torch.eye(10)[sparse_label]) # Output is double tensor\n",
    "\n",
    "# Simple method\n",
    "print(\"One-hot vector (Simple version) \\n\", torch.nn.functional.one_hot(sparse_label)) # Output is long tensor\n",
    "\n",
    "# Change mnist dataset's label to one hot vector without torch.nn.functional and set the dtype and device\n",
    "\n",
    "y_train_one_hot = torch.eye(10)[y_train].to(dtype=dtype, device=device)\n",
    "y_test_one_hot = torch.eye(10)[y_test].to(dtype=dtype, device=device)\n",
    "\n",
    "# Check the changes\n",
    "print(\"train label one hot vector's shape : \", y_train_one_hot.shape)\n",
    "idx = np.random.randint(0, y_train.shape[0])\n",
    "print(\"train one hot vector example, \" + str(idx) + \"th label\")\n",
    "print(y_train_one_hot[idx])\n",
    "\n",
    "print(\"test label one hot vector's shape : \", y_test_one_hot.shape)\n",
    "idx = np.random.randint(0, y_test.shape[0])\n",
    "print(\"test one hot vector example, \" + str(idx) + \"th label\")\n",
    "print(y_test_one_hot[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 100\n",
    "display_step = 10\n",
    "\n",
    "# Data dimension\n",
    "D_in =  calculate_vector_size(shape) # Data input's dimension\n",
    "D_out = 10 # Data output's dimemsion - One-hot vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the model\n",
    "## Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "class LogisticModel(torch.nn.Module):\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(LogisticModel, self).__init__()\n",
    "        # Initialize model weights\n",
    "        \n",
    "        # Arguments\n",
    "        # D_in : Input dimension of the model\n",
    "        # D_out : Output dimension of the model\n",
    "        \n",
    "        # Hint\n",
    "        # torch.nn.Softmax(dim)\n",
    "        # Reference : https://pytorch.org/docs/stable/nn.html?highlight=torch.nn.softmax#torch.nn.Softmax\n",
    "        \n",
    "        self.linear = torch.nn.Linear(in_features=D_in, out_features=D_out)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Calculate the model outputs\n",
    "        \n",
    "        # Arguments\n",
    "        # x : Input of the model (vectorized data)\n",
    "        \n",
    "        output = self.linear(x)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Define the loss using one-hot vector\n",
    "class Cross_Entropy_Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cross_Entropy_Loss, self).__init__()\n",
    "    def forward(self, y_pred, y):\n",
    "        # Loss for each example\n",
    "        loss = torch.sum(-1 * y * torch.log(y_pred), axis=1)\n",
    "\n",
    "        # Mean the loss of each example\n",
    "        loss = torch.mean(loss)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "# Make the model\n",
    "model = LogisticModel(D_in, D_out).to(dtype=dtype, device=device)\n",
    "\n",
    "# Set the loss function as Cross_Entropy_Loss\n",
    "criterion = Cross_Entropy_Loss()\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "epoch  10 \t loss :  1.0319121577127495\n",
      "epoch  20 \t loss :  0.7511135198759621\n",
      "epoch  30 \t loss :  0.6390395732304093\n",
      "epoch  40 \t loss :  0.5766996866681102\n",
      "epoch  50 \t loss :  0.5361313040701295\n",
      "epoch  60 \t loss :  0.5071995140261247\n",
      "epoch  70 \t loss :  0.4852900673496074\n",
      "epoch  80 \t loss :  0.46798092037001715\n",
      "epoch  90 \t loss :  0.45386962606932824\n",
      "epoch  100 \t loss :  0.4420834015073565\n",
      "Finish training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    # Initialize the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute Forward process and calculate the loss\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train_one_hot)\n",
    "\n",
    "    # Record the loss\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Display the loss\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        print(\"epoch \", epoch + 1, \"\\t loss : \", losses[-1])\n",
    "    \n",
    "    # Compute backward process and update weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_corrects = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    # Compute the forward process\n",
    "    \n",
    "    # Get predicted labels from outputs\n",
    "    # Hint : torch.max or torch.argmax\n",
    "    \n",
    "    # Check the number of correct labels and total label\n",
    "    \n",
    "    # Show the accuracy\n",
    "    print(\"Test accuracy : \", (test_corrects / test_total) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix's input is numpy object!\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Calculate the outputs and extract labels from that\n",
    "    # Fill the code\n",
    "    \n",
    "    print(\"Predicted label results\")\n",
    "    print(y_test_pred)\n",
    "    print(\"Target label results\")\n",
    "    print(y_test)\n",
    "    \n",
    "    print(\"Confusion matrix result\")\n",
    "    print(confusion_matrix(y_test.cpu().numpy(), y_test_pred.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 prediction examples\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        # Make random index of test data\n",
    "        \n",
    "        # Make a prediction\n",
    "        \n",
    "        # Show a image\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        \n",
    "        # On left side, we show the random image\n",
    "        \n",
    "        # On right side, we show the model's probability prediction\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Show the predicted label and true label\n",
    "        print(\"Predicted label : \", predictions.item())\n",
    "        print(\"True label : \", y_test[idx].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler implementation (with torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model with torch.nn.Sequential\n",
    "\n",
    "# Set the loss function with torch.nn.CrossEntropyLoss((log)Softmax + NLLLoss)\n",
    "# Reference : https://pytorch.org/docs/stable/nn.html?highlight=torch.nn.crossentropyloss#torch.nn.CrossEntropyLoss\n",
    "\n",
    "# Set optimizer to gradient descent optimizer\n",
    "\n",
    "\n",
    "losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    # Initialize the optimizer\n",
    "    \n",
    "    # Compute Forward process and calculate the loss\n",
    "\n",
    "    # Record the loss\n",
    "    \n",
    "    # Display the loss\n",
    "    \n",
    "    # Compute backward process and update weights\n",
    "    \n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss (Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
